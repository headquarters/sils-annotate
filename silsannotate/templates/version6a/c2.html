{% extends "{0}/layout.html".format(dir_prefix) %}
{% block title %}A Guide to Writing the Dissertation Literature Review{% endblock %}
{% block body %}
<div id="container" class="clearfix">
    <article>
        <h1>A Guide to Writing the Dissertation Literature Review</h1>
        <h4>Practical Assessment, Research & Evaluation, Volume 14, Number 13, June 2009</h4>
        <p><b>Justus J. Randolph, Walden University</b></p>
        <br>
        <h2>Abstract</h2>
        <p>Writing a faulty literature review is one of many ways to derail a dissertation. This article summarizes some pivotal information on how to write a high-quality dissertation literature review. It begins with a discussion of the purposes of a review, presents taxonomy of literature reviews, and then discusses the steps in conducting a quantitative or qualitative literature review. The article concludes with a discussion of common mistakes and a framework for the self-evaluation of a literature review.</p>
        <br>
        <br>


        <p>Writing a faulty literature review is one of many ways to derail a dissertation. If the literature review is flawed, the remainder of the dissertation may also be viewed as flawed, because "a researcher cannot perform significant research without first understanding the literature in the field" <a href="#4" class = "reference">(Boote & Beile, 2005, p. 3)</a>. Experienced thesis examiners know this. In a study of the practices of Australian dissertation examiners, <a href="#18" class = "reference">Mullins and Kiley (2002)</a> found that,</p>

        <blockquote>Examiners typically started reviewing a dissertation with the expectation that it would pass; but a poorly conceptualized or written literature review often indicated for them that the rest of the dissertation might have problems. On encountering an inadequate literature review, examiners would proceed to look at the methods of data collection, the analysis, and the conclusions more carefully. <a href="#4" class = "reference">(Boote & Beile, 2005, p. 6)</a></blockquote>

        <p>Given the importance of literature reviews in both dissertations and journal articles, it may be surprising that so many of them are faulty. <a href="#4" class = "reference">Boote and Beile (2005)</a> claim that "the dirty secret known by those who sit on dissertation committees is that most literature reviews are poorly conceptualized and written" (p. 4). Further, dissertations and theses are not the only types of publications that suffer from poor literature reviews. Many literature reviews in manuscripts submitted for publication in journals are also flawed—see <a href="#1" class = "reference">Alton-Lee (1998)</a>, <a href="#13" class = "reference">Grante and Graue (1999)</a>, and <a href="#14" class = "reference">LeCompte, Klinger, Campbell, and Menck (2003)</a>.</p>

        <p>Given that so many literature reviews are poorly done, it is surprising there is not more published information on how to write a literature review. <a href="#4" class = "reference">Boot and Beile (2005)</a> write,</p>

        <blockquote>Doctoral students seeking advice on how to improve their literature reviews will find little published guidance worth heeding. . . . Most graduate students receive little or no formal training in how to analyze and synthesize the research literature in their field, and they are unlikely to find it elsewhere. (p. 5)</blockquote>

        <p>Not only is there a lack of published information to guide writers of literature reviews, the labor intensive process of writing one compounds the problem. <a href="#11" class = "reference">Gall, Borg, and Gall (1996)</a> estimate that completion of an acceptable dissertation literature review will take between three and six months of effort.</p>

        <p>The purpose of this guide is to collect and summarize the most relevant information on how to write a dissertation literature review. I begin with a discussion of the purposes of a review, present <a href="#6" class = "reference">Cooper’s (1988)</a> Taxonomy of Literature Reviews, and discuss the steps in conducting a quantitative or qualitative literature review. A discussion of common mistakes and a framework for the self-evaluation of literature reviews concludes the article.</p>

        <h2>Purposes for Writing a Literature Review</h2>

        <p>Conducting a literature review is a means of demonstrating an author’s knowledge about a particular field of study, including vocabulary, theories, key variables and phenomena, and its methods and history. Conducting a literature review also informs the student of the influential researchers and research groups in the field. Finally, with some modification, the literature review is a “legitimate and publishable scholarly document” <a href="#14" class = "reference">(LeCompte & colleagues, 2003, p. 124)</a>.</p>

        <p>Apart from the above reasons for writing a review (i.e., proof of knowledge, a publishable document, and the identification of a research family), the scientific reasons for conducting a literature review are many. <a href="#11" class = "reference">Gall, Borg, and Gall (1996)</a> argue that the literature review plays a role in:</p>
        <ul>
        <li>delimiting the research problem,</li>
        <li>seeking new lines of inquiry,</li>
        <li>avoiding fruitless approaches,</li>
        <li>gaining methodological insights,</li>
        <li>identifying recommendations for further research, and</li>
        <li>seeking support for grounded theory.</li>
        </ul>

        <p><a href="#10" class = "reference">Hart (1998)</a> contributes additional reasons for reviewing the literature, including:</p>
        <ul>
        <li>distinguishing what has been done from what needs to be done,</li>
        <li>discovering important variables relevant to the topic,</li>
        <li>synthesizing and gaining a new perspective,</li>
        <li>identifying relationships between ideas and practices,</li>
        <li>establishing the context of the topic or problem,</li>
        <li>rationalizing the significance of the problem,</li>
        <li>enhancing and acquiring the subject vocabulary,</li>
        <li>understanding the structure of the subject,</li>
        <li>relating ideas and theory to applications,</li>
        <li>identifying the main methodologies and research techniques that have been used, and</li>
        <li>placing the research in a historical context to show familiarity with state-of-the-art developments. (p. 27)</li>
        </ul>

        <p>Another purpose for writing a literature review not mentioned above is that it provides a framework for relating new findings to previous findings in the discussion section of a dissertation. Without establishing the state of the previous research, it is impossible to establish how the new research advances the previous research.</p>

        <h2>Taxonomy of Literature Reviews</h2>

        <p>An effective method to begin planning a research review is to consider where the proposed review fits into <a href="#6" class = "reference">Cooper’s (1988)</a> Taxonomy of Literature Reviews. As shown in <a href = "#table1" target="_self">Table 1</a>, Cooper suggests that literature reviews can be classified according to five characteristics: <i>focus, goal, perspective, coverage, organization,</i> and <i>audience</i>. In <a href = "#table1" target="_self">Table 1</a>, each characteristic is listed on the left, with the levels of the characteristics on the right. In the paragraphs that follow, each of these literature review characteristics are described in more detail.</p>
        <p>
            <img id="table1" src="https://raw.githubusercontent.com/headquarters/sils-annotate/master/silsannotate/static/version5/img/tables/c2/c2-1.png" alt="Table 1" />
        </p>

        <h3>Focus</h3>
        <p>The first characteristic is the focus of the review. <a href="#6" class = "reference">Cooper (1988)</a> identifies four potential foci: <i>research outcomes, research methods, theories,</i> or <i>practices or applications</i>.</p>

        <p>Literature reviews that focus on research outcomes are perhaps the most common. In fact, the <a href="#9" class = "reference">Educational Resources Information Center (1982, p. 85)</a> defines a literature review as an "information analysis and synthesis, <i>focusing on findings</i> and not simply bibliographic citations, summarizing the substance of the literature and drawing conclusions from it" (italics mine). The Educational Resources Information Center suggests that, in terms of a developing a research rationale, an outcomes-oriented review may help identify a lack of information on a particular research outcome, thus establishing a justifiable need for an outcome study.</p>

        <p>Methodological reviews concentrate on research methods—Cooper’s second focus category. In a methodological review, research methods in the chosen field are investigated to identify key variables, measures, and methods of analysis and inform outcomes-oriented research. The methodological review is also helpful to identify methodological strengths and weaknesses in a body of research, and examine how research practices differ across groups, times, or settings. Methodological reviews, combined with outcome reviews, may also identify ways in which the methods inform the outcomes. A methodological review may also lead to sound rationale that can justify proposed dissertation research, if it turns out that the previous research has been methodologically flawed.</p>

        <p>A review of theories, Cooper’s third focus, can help establish what theories already exist, the relationships between them, and to what degree the existing theories have been investigated. A theoretical review is appropriate if, for example, the dissertation aims to advance a new theory. In terms of the research rationale, a theoretical review can help establish a lack of theories or reveal that the current theories are insufficient, helping to justify that a new theory should be put forth.</p>

        <p>Finally, literature reviews can be focused on practices or applications. For example, a review might concentrate on how a certain intervention has been applied or how a group of people tend to carry out a certain practice. In terms of a research rationale, this fourth type of review can help establish a practical need not currently being met.</p>

        <p>While a dissertation review typically has a primary focus, it may also be necessary to address all or some of the foci mentioned above. For example, a review with an outcomes-oriented focus would likely also deal with the methodological flaws that might affect an outcome. An outcomes-oriented review may also deal with theories related to the phenomenon being investigated and introduce the practical applications of the knowledge that will ultimately be gained from the dissertation.</p>

        <h3>Goal</h3>
        <p>The goal of many reviews is to integrate and generalize findings across units, treatments, outcomes, and settings; to resolve a debate within a field; or to bridge the language used across fields. Meta-analysis, for example, is an often-used review technique in which the primary goal is to integrate quantitative outcomes across studies. In other reviews the goal may be to critically analyze previous research, identify central issues, or explicate a line of argument within a field.</p>

        <p>A dissertation review often has multiple goals. If the dissertation is solely a review, the author may be primarily interested in integration, but it also may be necessary to critically analyze the research, identify central issues, or explicate an argument. However, if a dissertation author is using the literature review to justify a later investigation, the goal will place more emphasis on critically analyzing the literature, perhaps to identify a weakness and propose to remedy that weakness with dissertation research. Either way, the author must integrate reviews to present the reader with the big picture. Without integration, the map of the research landscape would be as large as the research landscape itself.</p>

        <h3>Perspective</h3>

        <p>In qualitative primary research, review authors often decide to reveal their own preexisting biases and discuss how those biases might have affected the review. Or, as is often the case in quantitative primary research, authors can attempt to take a neutral perspective and present the review findings as fact. The perspective taken depends largely on whether the review is conducted in the quantitative or qualitative traditions. Since secondary research (i.e., review research) methods parallel primary research methods, it makes sense for the author of a qualitative review to follow the qualitative tradition and reveal biases and the author of a quantitative review to follow the quantitative tradition and claim a neutral position. This decision will be dictated by the particular case.</p>

        <h3>Coverage</h3>

        <p>Deciding how wide to cast the net is a critical step in conducting a review. Cooper proposes four coverage scenarios. In an <i>exhaustive review</i>, the reviewer promises to locate and consider every available piece of research on a certain topic, published or unpublished. However, finding every piece of research could take more time than is available. The key to the exhaustive review is to define the population in such a way that it is bounded and the number of articles to review is manageable. <a href="#6" class = "reference">Cooper (1988)</a> calls this an <i>exhaustive review with selective citation</i>. For example, the reviewer might choose only to look at articles published in journals, but not conference papers; however, a theoretical reason to exclude conference papers is advised.</p>

        <p>A third coverage approach is to consider a <i>representative sample</i> of articles and make inferences about the entire population of articles from that sample. However, random sampling is far from foolproof. A perhaps more certain approach is to gather evidence that demonstrates that the representative sample is actually representative. The most sound approach may be to do both.</p>

        <p>Cooper’s fourth article selection approach is to take a <i>purposive sample</i> in which the reviewer examines only the central or pivotal articles in a field. The key here is to convince the reader that the selected articles are, in fact, the central or pivotal articles in a field, and just as importantly that the articles not chosen are not central or pivotal.</p>

        <h3>Organization</h3>

        <p>There are many formats in which to organize a review. Three of the most common are the <i>historical format, the conceptual format,</i> and <i>the methodological format</i>. In the historical format the review is organized chronologically. Clearly, this is preferred when the emphasis is on the progression of research methods or theories, or on a change in practices over time.</p>

        <p>A second common organizational scheme is built around concepts. For example, the review may be organized around the propositions in a research rationale or, in a theoretically-focused review, organized according to the various theories in the literature. Finally, the literature review can be organized methodologically, as in an empirical paper (i.e., introduction, method, results, and discussion). In some cases, it may be most effective to mix and/or match these organizational formats. For example, the reviewer might begin with an introduction, define the method, and present the results in a historical or conceptual format, then move on to the discussion of results. This organizational format is often used in meta-analytic reports.</p>

        <h3>Audience</h3>

        <p>The final characteristic of <a href="#6" class = "reference">Cooper’s (1988)</a> Taxonomy of Literature Reviews is <i>audience</i>. For a dissertation, the supervisor and reviewers of the dissertation are the primary audience. The scholars within the field that the dissertation relates to are the secondary audience. Avoid writing the dissertation literature review for a general, non-academic audience. What constitutes a good book is probably not what constitutes a good dissertation, and vice versa.</p>

        <h2>How to Conduct a Literature Review</h2>

        <p>Take a look at the list below. Does it look familiar? It could be a step-by-step guide on how to conduct primary research, but in fact it describes the stages of conducting a literature review (see <a href="#5" class = "reference">Cooper, 1984</a>).</p>
        <ol>
        <li>Problem formulation</li>
        <li>Data collection</li>
        <li>Data evaluation</li>
        <li>Analysis and interpretation</li>
        <li>Public presentation</li>
        </ol>


        <p>If one thing must be realized about conducting and reporting a literature review it is that <b>the stages for conducting and reporting a literature review parallel the process for conducting primary research</b>. With a few modifications, what one knows about conducting primary research applies to conducting secondary research (i.e., a literature review). The key components are (a) a rationale for conducting the review; (b) research questions or hypotheses that guide the research; (c) an explicit plan for collecting data, including how units will be chosen; (d) an explicit plan for analyzing data; and (e) a plan for presenting data. Instead of human participants, for example, the units in a literature review are the articles that are reviewed. Validity and reliability, the same issues that apply to primary research, also apply to secondary research. And, as in primary research, the stages may be iterative and not necessarily completed in the order presented above.</p>

        <p><a href = "#table2" target="_self">Table 2</a>, from <a href="#5" class = "reference">Cooper (1984)</a>, is a framework to guide the completion of the four research stages of a literature review. On the left, the table identifies the general characteristics of each research stage: the research questions asked, the primary functions of each stage, the procedural differences that may lead to differing conclusions, and the potential sources of invalidity at each stage. For each of the characteristics, the remaining columns of the table pose key questions to guide the review writer in: <i>problem formation, data collection, data evaluation, analysis and interpretation</i>, and <i>public presentation</i>. Following sections discuss in more detail the steps <a href="#5" class = "reference">Cooper (1984)</a> suggests for conducting a literature review.</p>
        <p>
            <img id="table2" src="https://raw.githubusercontent.com/headquarters/sils-annotate/master/silsannotate/static/version5/img/tables/c2/c2-2.png" alt="Table 2" />
        </p>

        <h3>Problem formulation (for the literature review)</h3>

        <p>Once the appropriate type of review has been identified (see Cooper’s taxonomy in <a href = "#table1" target="_self">Table 1</a>), the focus shifts to problem formulation. In this step the reviewer decides what questions the literature review will answer and determines explicit criteria to dictate the inclusion, or exclusion, of an article included in the review. At this point it is important to make a distinction between literature review questions (i.e., questions that can be answered by reviewing the secondary research) and empirical research questions (i.e., questions that can be answered only through primary research). The literature review is the primary source of the empirical research question <a href="#24" class = "reference">(Randolph, 2007c)</a>.</p>

        <p>Problem formation begins with the determination of the questions that will guide the literature review. These questions should be influenced significantly by the goal and focus of the review. For example, if the goal of the review is to integrate research outcomes, then a meaningful research question might be: <i>From the previous literature, what is the effect of intervention X on outcomes Y and Z?</i> If the goal is to critically analyze the research methods used in previous literature, questions might include: <i>What research methods have been used in the past to investigate phenomenon X?</i> and <i>What are the methodological flaws of those methods?</i> If the literature review focus is on theories and the goal is to identify central issues, then a legitimate research question might be: <i>What are the central theories that have been used to explain phenomenon X?</i> At this point it is wise to search for literature reviews that may have already answered these or related questions.</p>

        <p>The second step in problem formation is to explicitly determine the <i>criteria for inclusion and exclusion</i>. In other words, determine which articles will be included in the review and which articles will be excluded. The particular criteria are influenced by the review’s focus, goals, and coverage. Below is an example of the criteria for inclusion and exclusion used in a review of the research on the use of student response cards <a href="#23" class = "reference">(Randolph, 2007b)</a>:</p>

        <blockquote>Studies were included in the quantitative synthesis if they met each of the following criteria:</blockquote>
        <ol>
        <li>The study reported means and standard deviations or provided enough information to calculate means and standard deviations for each condition.</li>
        <li>The use of write-on response cards, preprinted response cards, or both was the independent variable.</li>
        <li>Voluntary single-student oral responding (i.e., hand raising) was used during the control condition.</li>
        <li>The study reported results on at least one of the following dependent variables: participation, quiz achievement, test achievement, or intervals of behavioral disruptions.</li>
        <li>The report was written in English.</li>
        <li>The data from one study did not overlap data from another study.</li>
        <li>The studies used repeated-measures-type methodologies.</li>
        <li>For separate studies that used the same data (e.g., a dissertation and a journal article based on the same dataset), only the study with the most comprehensive reporting was included to avoid the overrepresentation of a particular set of data. (pp. 115-116)</li>
        </ol>


        <p>The inclusion/exclusion criteria should be explicit and comprehensive enough so that any article that comes to light could be included or excluded solely based on those criteria. Further, the criteria should include enough detail so that two people, given the same set of articles, would identify virtually the same subset of articles. In fact, in reviews where reliability is essential, such as when an entire dissertation or thesis is a review, researchers often recruit other individuals to test the reliability of the inclusion/exclusion system, then compare the resultant subsets to reveal inconsistencies, revising the criteria accordingly.</p>

        <p>It is likely that creating a valid set of inclusion/exclusion criteria will require considerable trial and error pilot testing. Often, ambiguities in the criteria will result in articles that are inadequately omitted. Recursively pilot-testing the criteria is time-consuming, but much less so than starting over after much data have been painstakingly collected and analyzed.</p>

        <h3>Data collection</h3>

        <p>The goal of the data collection stage is to collect an exhaustive, semi-exhaustive, representative, or pivotal set of relevant articles. As in primary research, the researcher of secondary data must not only devise a systematic plan for data collection, he or she must accurately document how the data were collected. The reviewer is advised to describe the data collection procedure with such detail that, theoretically, other reviewers following the same procedures under the same conditions would find an identical set of articles.</p>

        <p>The data collection process often begins with an electronic search of academic databases and the Internet. (Because relevant databases vary within fields, I will not discuss them here.) When these searches are conducted, careful, accurate records must be kept of the date of each search, the databases searched, the key words and key word combinations used, and the number of records resulting from each search.</p>

        <p>In my experience, electronic searches lead to only about ten percent of the articles that will comprise an exhaustive review. There are several approaches to locate the remaining 90%. The most effective method may be to search the references of the articles that were retrieved, determine which of those seem relevant, find those, read their references, and repeat the process until a point of saturation is reached—a point where no new relevant articles come to light.</p>

        <p>When electronic and reference searching is exhausted, the reviewer is advised to share the list of references with colleagues and experts in the field to determine if they detect any missing articles. Sending a query to the main Listserv of experts in the relevant field, with a request that they identify missing articles, is often effective to yield additional references. It is also advisable to share the final list of potentially relevant articles with dissertation supervisors and reviewers, as they, too, may be aware of additional relevant literature.</p>

        <p>The data collection process can stop when the point of saturation is reached, and the reviewer has sufficient evidence to convince readers that everything that can reasonably be done to identify all relevant articles has been diligently undertaken. Of course, it is likely that new articles will come to light after the data collection period has concluded. However, unless the new article is critically important, I suggest leaving it out. Otherwise, the reviewer may have to open the floodgates and start anew the data collection process.</p>

        <p>Now the reviewer must devise a system to further cull the collected articles. For example, to separate the potentially relevant from the obviously irrelevant studies, the reviewer might read every word of every electronic record, just the abstract, just the title, or some combination. Whichever method is chosen, the reviewer is advised to accurately document the process undertaken. When the obviously irrelevant articles have been identified and discarded, the reviewer can begin to determine which of the remaining articles will be included in the literature review. Again, when reliability is critical, it is common for two or more other qualified individuals to determine which articles in the new subset meet the criteria for inclusion and exclusion to estimate and consider the level of interrater agreement. (<a href="#19" class = "reference">Neuendorf [2002]</a> provides a thorough discussion of methods to quantify interrater agreement.) When the reviewer is satisfied that the final subset of relevant articles is complete, the data evaluation stage can begin.</p>

        <h3>Data evaluation</h3>

        <p>In the data evaluation stage the reviewer begins to extract and evaluate the information in the articles that met the inclusion criteria. To begin, the reviewer devises a system for extracting data from the articles. The type of data extracted is determined by the focus and goal of the review. For example, if the focus is research outcomes and the goal is integration, one will extract research outcomes data from each article and decide how to integrate those outcomes. As the data are evaluated, the reviewer is advised to document the types of data extracted and the process used. Because it requires extensive detail, this documentation is sometimes recorded using separate coding forms and a coding book, which are included as dissertation appendices. Or, the documentation may be included within the main body of the dissertation.</p>

        <p>Whether the procedures for extracting the data are recorded in a separate coding book or included within the body of the dissertation, the level of detail should be such that, actually or theoretically, a second person could arrive at more or less the same results by following the recorded procedure.</p>

        <p>A coding book is an electronic document, such as a spreadsheet, or a physical form on which data are recorded for each article. The coding book documents the types of data that will be extracted from each article, the process used to do so, and the actual data. If the focus of the research is on outcomes, for example, the coding book should include one or more variables that track the extraction of research outcomes. The literature review, of course, will require the extraction of additional types of data, especially data that identify the factors that may influence research outcomes. For example, in experimental research the reviewer’s coding book will extract from each article the measurement instruments used; the independent, dependent, and mediating/moderating variables investigated; the data analysis procedures; the types of experimental controls; and other data. Of course, the influencing factors vary depending on the topic.</p>

        <p>Examining previous literature reviews, meta-analyses, or coding books is helpful to understand the scope and organization of a coding book. A freely-downloadable example of a coding book and coding sheet used in a methodological review dissertation can be found from <a href="#22" class = "reference">Randolph (2007a)</a>.</p>

        <p>It is essential to carefully consider the types of data to be extracted from each article, and to thoroughly pilot test the coding book. The extraction process tends to reveal other types of data that should be extracted, and may necessitate revision of the coding book and the recoding all articles. Further, if interrater reliability is important, the reviewer should alternately pilot test and revise the coding book until acceptable levels of interrater reliability are achieved.</p>

        <p>Literature reviews commonly examine data about the quality of research. However, there are conflicting views about the inclusion of low quality articles in a review. (See <a href = "#table3" target="_self">Table 3</a> for a rubric on rating the quality of articles.) Some, like Cooper, suggest including only high quality articles in a study. Others suggest including both high quality and low quality studies and reporting the differences between the two. If there is not a difference, the data can be grouped together. If there is a difference, however, the reviewer may want to separately report results from the high-quality articles and low-quality articles.</p>

        <p>A goal of many reviews is to integrate or synthesize research outcomes. Thus, a common metric or measure must be identified into which all of the research outcomes can be translated. In a quantitative synthesis, for example, the common metric might be the difference in proportions between control and treatment groups.</p>

        <p>
            <img id="table3" src="https://raw.githubusercontent.com/headquarters/sils-annotate/master/silsannotate/static/version5/img/tables/c2/c2-4.png" alt="Table 3" />
        </p>

        <h3>Data analysis and interpretation</h3>

        <p>Finally, at the data analysis and interpretation stage, the reviewer attempts to make sense of the extracted data. If the goal of the literature review is integration, the reviewer now integrates the data. Depending on the type of data extracted, a quantitative, qualitative, or mixed-methods synthesis will be performed. More information about analyzing data for quantitative and qualitative literature reviews is given later.</p>

        <h3>Public presentation</h3>

        <p>At this stage the review author determines which information is more important and will be presented and which information is less important information and can be left out. In a dissertation literature review, the author can be liberal about how much information to include. As discussed earlier, literature reviews are commonly organized <i>historically, conceptually,</i> or <i>methodologically</i>.</p>

        <p>As mentioned earlier, the primary audience for the literature review is the dissertation supervisor and other dissertation reviewers. The secondary audience is other scholars in the field. The dissertation review can be revised later to meet the needs of a more general audience.</p>

        <h3>Formulating and justifying empirical research questions</h3>

        <p>The literature review, combined with the research problem, should lead to the formulation of empirical research questions. Although Cooper does not include this stage in his <a href="#6" class = "reference">(1988) Taxonomy</a> of Literature Reviews, it is an essential part of a dissertation. At this point, the dissertation author explains, using evidence from the review, how the dissertation makes a meaningful contribution to knowledge in the field. The <a href="#2" class = "reference">American Education Research Association (2006)</a> explains some of the ways new research can contribute to existing research:</p>

        <blockquote>If the study is <b>a contribution to an established line of theory and empirical research</b>, it should make clear what the contributions are and how the study contributes to testing, elaborating, or enriching that theoretical perspective.</blockquote>

        <blockquote>If a study is intended to <b>establish a new line of theory</b>, it should make clear what that new theory is, how it relates to existing theories and evidence, why the new theory is needed, and the intended scope of its application.</blockquote>

        <blockquote>If the study is <b>motivated by practical concerns</b>, it should make clear what those concerns are, why they are important, and how this investigation can address those concerns.</blockquote>

        <blockquote>If the study is <b>motivated by a lack of information about a problem or issue</b>, the problem formation should make clear what information is lacking, why it is important, and how this investigation will address the need for information. (p. 3)</blockquote>

        <h2>Quantitative Literature Reviews</h2>

        <p>Two common types of quantitative reviews are narrative reviews and meta-analytic reviews. Before the method of meta-analysis became prevalent, almost all quantitative reviews were narrative. According to <a href="#11" class = "reference">Gall, Borg, and Gall (1996)</a>, narrative reviews:</p>

        <blockquote>emphasized better-designed studies, and organized their results to form a composite picture of the state of the knowledge on the problem or topic being reviewed. The number of statistically significant results, compared with the number of nonsignificant results, may have been noted. Each study may have been described separately in a few sentences or a paragraph. (pp. 154-155)</blockquote>

        <p>However, despite their frequent use, narrative reviews tend to be significantly affected by the reviewer’s subjectivity. Research has indicated that the conclusions of one narrative review can differ completely from another review written by a different author, even when exactly the same articles are reviewed <a href="#15" class = "reference">(Light & Pillemer, 1984)</a>.</p>

        <p>Today, meta-analytic reviews have taken the forefront. In a meta-analytic review, the reviewer (a) collects a representative or comprehensive sample of articles, (b) codes those articles according to a number of aspects (e.g., study quality, type of intervention used, type of measure used, study outcomes), (c) finds a common metric (e.g., a standardized mean difference effect size) that allows the study outcomes to be synthesized, and then (d) examines how the characteristics of a study covary with study outcomes.</p>

        <p><a href = "#figure1" target="_self">Figure 1</a>, below, shows an example of a graph often used in meta-analysis. The forest plot illustrates the types of information typically yielded through meta-analyses. <a href = "#figure1" target="_self">Figure 1</a>, from <a href="#23" class = "reference">Randolph 2007b</a>, illustrates the outcomes of 13 studies that investigated the effects of response cards on academic achievement (in this case, quiz scores). The triangle represents the effect and the lines on either side indicate the 95% confidence intervals for that effect. The common metric used for the forest plot is a standardized mean difference effect size called <i>Cohen’s d</i>. At the bottom of the figure is the weighted average effect size (i.e., the integrated outcome) of all 13 studies, approximately 1.1, which means that the students scored about 1.1 standard deviations higher on their quizzes when using response cards than when not using response cards.</p>

        <p>As illustrated in <a href = "#figure1" target="_self">Figure 1</a>, meta-analysis is a useful way to synthesize and analyze a body of quantitative research (<a href="#7" class = "reference">Cooper & Hedges, 1994a</a>; <a href="#12" class = "reference">Glass, McGaw, & Smith, 1981</a>; <a href="#16" class = "reference">Lipsey & Wilson, 2001</a>; or <a href="#25" class = "reference">Rosenthal, 1991</a>, are all excellent guidebooks for conducting meta-analyses). However, criticisms of meta-analysis include that it is subject to publication bias (i.e., that statistically significant results tend to be published more than nonstatistically significant results) and that is too mechanistic. Some, such as <a href="#26" class = "reference">Slavin (1986)</a>, wisely suggest combining meta-analytic and narrative techniques. For example, one might quantitatively synthesize each study, but also provide a thorough narrative description of particularly relevant studies.</p>

        <p>
            <img id="figure1" src="https://raw.githubusercontent.com/headquarters/sils-annotate/master/silsannotate/static/version5/img/tables/c2/c2-3.png" alt="Figure 1" />
        </p>

        <h2>Qualitative Literature Reviews</h2>

        <p>When a body of literature is primarily qualitative, or contains a mixture of quantitative and qualitative results, it may be necessary to conduct a qualitative review, either alone or as a complement to a quantitative review. This section presents two methods for conducting qualitative literature reviews. The first method was first put forth by <a href="#21" class = "reference">Ogawa and Malen (1991)</a>. The second method, which I put forth, borrows the method of phenomenological research and applies it to conducting a literature review. Another useful resource for conducting qualitative literature reviews, not described here, is <a href="#20" class = "reference">Noblit and Hare (1988)</a>.</p>

        <h3>Ogawa and Malen’s method</h3>

        <p><a href="#11" class = "reference">Borg, Gall, and Borg (1996)</a> have broken down <a href="#21" class = "reference">Ogawa and Malen’s (1991)</a> method into the eight steps discussed below. Note that these steps parallel the basic steps in qualitative research.</p>

        <p><i>Step 1: Create an audit trail.</i> In this step, the reviewer carefully documents all of the steps that are taken. The audit trail serves as documentation to make clear the evidence that supports each finding, where that evidence can be found, and how that evidence was interpreted.</p>

        <p><i>Step 2. Define the focus of the review.</i> The problem formation stage mentioned earlier is similar to this step. In this stage the constructs of the review are defined and, thereby, it is determined what to include in the review and what to leave out.</p>

        <p><i>Step 3: Search for relevant literature.</i> This step is similar to the data collection stage mentioned earlier. According to <a href="#21" class = "reference">Ogawa and Malen (1991)</a>, in addition to qualitative research reports, nonresearch reports such as memos, newspaper articles, or meeting minutes should also be included in the review and not necessarily regarded as having less value than qualitative research reports.</p>

        <p><i>Step 4: Classify the documents.</i> In this step the reviewer classifies the documents according to the types of data they represent. For example, some documents might be first-hand reports of qualitative research, others may be policy statements about the issue in question, and still other types of data might describe projects surrounding the issue.</p>

        <p><i>Step 5: Create summary databases.</i> This step is similar to the data evaluation stage. In this stage the reviewer develops coding schemes and attempts to reduce the information in the relevant documents. On this point, <a href="#11" class = "reference">Borg, Gall, and Borg (1996)</a> wrote,</p>

        <blockquote>You cannot simply read all these documents, take casual notes, and then write a literature review. Instead, you will need to develop narrative summaries and coding schemes that take into account all the pertinent information in the documents. The process is iterative, meaning, for example, that you might need to develop a coding scheme, apply it to the documents, revise it based on this experience, and re-apply it. (p. 159)</blockquote>

        <p><i>Step 6: Identify constructs and hypothesized causal linkages.</i> After summary databases have been created, the task is to identify the essential themes of the documents and create hypotheses about the relationships between the themes. The goal here, unlike meta-analysis, is to increase the understanding of the phenomena being investigated, not to integrate outcomes and identify factors that covary with outcomes.</p>

        <p><i>Step 7: Search for contrary findings and rival interpretations.</i> In the tradition of primary qualitative research, it is necessary to actively search for contrary findings and rival interpretations. One might, for example, reread the documents at this point to search for contrary evidence.</p>

        <p><i>Step 8: Use colleagues or informants to corroborate findings.</i> The last step in <a href="#21" class = "reference">Ogawa and Malen’s (1991)</a> method, corroborating findings, also parallels primary qualitative research. In this step, one shares a draft of the report with colleagues and informants, such as the authors of the documents included in the review, requesting that they critically analyze the review. In this way, based on the extent of agreement among the informants, the reviewer can confirm the degree to which the review’s conclusions are sound.</p>

        <h3>The phenomenological method for conducting a qualitative literature review</h3>

        <p>The goal of phenomenological research is to arrive at the essence of the lived experience of a phenomenon <a href="#17" class = "reference">(Moustakas, 1994)</a>. Applied as a review technique, the goal is to arrive at the essence of researchers’ empirical experiences with a phenomenon. In first-hand phenomenology, the individuals who have experienced a certain phenomenon are interviewed. In using phenomenology as a review technique, the unit of analysis is the research report rather than an individual who experienced the phenomenon. When using phenomenology as a review technique, the data come from an empirical research report rather than interview data.</p>

        <p>Not surprisingly, the steps of a phenomenological review mirror the steps of phenomenological research. Those steps are briefly described below:</p>

        <p><i>Step 1: Bracketing.</i> In phenomenological research, the first step is to identify the phenomenon to be investigated. The researcher then “brackets” his or her experience with the phenomenon by explaining his or her own experiences with and positions on the phenomenon.</p>

        <p><i>Step 2: Collecting data.</i> The next step is to collect data about the phenomenon. In primary phenomenological research, the researcher would interview a set of people who had experienced the phenomenon. In using the phenomenological method as a review tool, the reviewer would read the reports of scientists who have done research on the phenomenon. As in quantitative reviews, the reviewer still must decide on criteria for inclusion and define the research strategy.</p>

        <p><i>Step 3: Identifying meaningful statements.</i> The third step is to identify meaningful statements. The researcher might do this by highlighting empirical claims made about the phenomenon of interest and collecting those claims, word-for-word, in some kind of spreadsheet or qualitative software to make the data manageable.</p>

        <p><i>Step 4. Giving meaning.</i> After identifying meaningful statements, the next step is to give meanings to those statements. That is, the reviewer might put the meaningful statements into categories and then interpret and paraphrase them as groups.</p>

        <p><i>Step 5. Thick, rich description.</i> The final step is to create a thick, rich description of the essence of primary researchers’ experiences with the phenomenon. The goal is to describe the essence of the phenomenon as seen through the eyes of the researchers who investigated that phenomenon.</p>


        <h2>Mistakes Commonly Made in Reviewing Research Literature</h2>
        <p>In order to help the reviewer avoid mistakes in conducting a literature review, some of the most common mistakes are listed below. <a href="#11" class = "reference">Gall, Borg, and Gall (1996)</a> claim that the most frequent mistakes made in reviewing the literature are that the researcher:</p>
        <ol>
        <li>does not clearly relate the findings of the literature review to the researcher’s own study;</li>
        <li>does not take sufficient time to define the best descriptors and identify the best sources to use in review literature related to one’s topic;</li>
        <li>relies on secondary sources rather than on primary sources in reviewing the literature;</li>
        <li>uncritically accepts another researcher’s findings and interpretations as valid, rather than examining critically all aspects of the research design and analysis;</li>
        <li>does not report the search procedures that were used in the literature review;</li>
        <li>reports isolated statistical results rather than synthesizing them by chi-square or meta-analytic methods; and</li>
        <li>does not consider contrary findings and alternative interpretations in synthesizing quantitative literature. (pp. 161-162)</li>
        </ol>

        <h2>Evaluating a Literature Review</h2>
        <p><a href="#4" class = "reference">Bootes and Beile (2005)</a> have created a five-category rubric for evaluating a literature review. The categories are <i>coverage, synthesis, methodology, significance,</i> and <i>rhetoric</i>. The rubric is presented in <a href = "#table3">Table 3</a>. Boote and Beile used this scoring rubric to rate a random sample of 30 education-related academic dissertations. <a href = "#table4">Table 4</a> shows a summary of their results.</p>

        <p>
            <img id="table4" src="https://raw.githubusercontent.com/headquarters/sils-annotate/master/silsannotate/static/version5/img/tables/c2/c2-5.png" alt="Table 4" />
        </p>

        <p>How does your literature review measure up?</p>

        <br>

        <h2>References</h2>
        <p id="1">Alton-Lee, A. (1998). <a href = "http://eric.ed.gov/?id=EJ580724">A troubleshooter’s checklist for prospective authors derived from reviewers’ critical feedback.</a> Teaching and Teacher Education, 14(8), 887-890.</p>

        <p id="2">American Education Research Association. (2006). <a href = "http://www.sagepub.com/upm-data/13127_Standards_from_AERA.pdf">Standards for reporting on empirical social science research in AERA publications.</a> Educational Researcher, 35(6), 33-40. </p>

        <p id="3">Boote, D. N., & Beile, P. (2004, April). <a href = "https://scholar.google.com/scholar?cluster=12498304665020001803&hl=en&as_sdt=5,34&sciodt=0,34">The quality of dissertation literature reviews: A missing link in research preparation.</a> Paper presented at the annual meeting of the American Educational Research Association, San Diego, CA.</p>

        <p id="4">Boote, D. N., & Beile, P. (2005). <a href = "http://edr.sagepub.com/content/34/6/3.short">Scholars before researchers: On the centrality of the dissertation literature review in research preparation.</a> Educational Researcher, 34(6), 3-15.</p>

        <p id="5">Cooper, H. M., (1984). <a href = "http://books.google.com/books/about/The_integrative_research_review.html?id=XAxHAAAAMAAJ">The integrative research review: A systematic approach.</a> Applied social research methods series (Vol. 2). Beverly Hills, CA: Sage.</p>

        <p id="6">Cooper, H. M. (1988). <a href = "http://link.springer.com/article/10.1007/BF03177550">Organizing knowledge synthesis: A taxonomy of literature reviews.</a> Knowledge in Society, 1, 104-126.</p>

        <p id="7">Cooper, H., & Hedges, L. V. (Eds.). (1994a). <a href = "http://books.google.com/books/about/The_Handbook_of_Research_Synthesis.html?id=cQxN792ttyEC">The handbook of research synthesis.</a> New York: Sage.</p>

        <p id="8">Cooper, H., & Hedges, L. V. (1994b). <a href = "http://books.google.com/books/about/The_Handbook_of_Research_Synthesis.html?id=cQxN792ttyEC">Research synthesis as a scientific enterprise. In H. Cooper & L.V. Hedges (Eds.), The handbook of research synthesis (pp. 3-14).</a> New York: Sage.</p>

        <p id="9">Educational Resources Information Center. (1982). <a href = "http://eric.ed.gov/?id=ED348055">ERIC processing manual (Section 5: Cataloging).</a> Washington, DC.</p>

        <p id="10">Hart, C. (1998). <a href = "http://books.google.com/books/about/Doing_a_Literature_Review.html?id=tc8LS6qa_KIC">Doing a literature review: Releasing the social science research imagination.</a> London: Sage.</p>

        <p id="11">Gall, M. D., Borg, W. R., & Gall, J. P. (1996). <a href = "http://books.google.com/books/about/Educational_Research.html?id=2LcTy5kCmfkC">Education research: An introduction (6th ed.).</a> White Plains, NY: Longman.</p>

        <p id="12">Glass, G. V., McGaw, B., & Smith, M. L. (1981). <a href = "http://books.google.com/books/about/Meta_analysis_in_social_research.html?id=FQ5HAAAAMAAJ">Meta-analysis in social research.</a> Beverly Hills, CA: Sage.</p>

        <p id="13">Grant, C. A., & Graue, E. (1999). <a href = "http://www.jstor.org/stable/1170771?seq=1#page_scan_tab_contents">(Re)Viewing a review: A case history of the “Review of Educational Research”.</a> Review of Educational Research, 69(4), 384-396.</p>

        <p id="14">LeCompte, M. D., Klinger, J. K., Campbell S. A., & Menke, D. W. (2003). <a href = "http://rer.sagepub.com/content/73/2/123.full.pdf+html">Editor’s introduction.</a> Review of Educational Research, 73(2), 123-124.</p>

        <p id="15">Light, R. J., & Pillemer, D. B. (1984). <a href = "http://books.google.com/books/about/Summing_up.html?id=vPp9AAAAIAAJ">Summing up: The science of reviewing research.</a> Cambridge, MA: Harvard University Press.</p>

        <p id="16">Lipsey, M. W., & Wilson, D. B. (2001). <a href = "http://books.google.com/books/about/Practical_Meta_Analysis.html?id=G-PnRSMxdIoC">Practical meta-analysis.</a> Applied social research methods series (Vol. 49). Thousand Oaks, CA: Sage.</p>

        <p id="17">Moustakas, C. (1994). <a href = "https://books.google.com/books/about/Phenomenological_Research_Methods.html?id=pp11AwAAQBAJ">Phenomenological research methods.</a> Thousand Oaks, CA: Sage.</p>

        <p id="18">Mullins, G., & Kiley, M. (2002). <a href = "http://www.tandfonline.com/doi/abs/10.1080/0307507022000011507">“It’s a PhD, not a Nobel Prize”: How experienced examiners assess research theses.</a> Studies in Higher Education, 27(4), 369-386.</p>

        <p id="19">Neuendorf, K. A. (2002). <a href = "http://books.google.com/books/about/The_Content_Analysis_Guidebook.html?id=huPVtmu4sigC">The content analysis handbook.</a> Thousand Oaks, CA: Sage.</p>

        <p id="20">Noblit, G. W., & Hare, R. D., (1988). <a href = "http://books.google.com/books/about/Meta_Ethnography.html?id=fQQb4FP4NSgC">Meta-ethnography: Synthesizing qualitative studies.</a> Newbury Park, CA: Sage.</p>

        <p id="21">Ogawa, R. T. & Malen, B. (1991). <a href = "http://rer.sagepub.com/content/61/3/265.short">Towards rigor in reviews of multivocal literature: Applying the exploratory case method.</a> Review of Educational Research, 61, 265-286.</p>

        <p id="22">Randolph, J. J. (2007a). <a href = "http://www.archive.org/details/randolph_dissertation">Computer science education research at the crossroads: A methodological review of computer science education research: 2000-2005.</a> (Doctoral dissertation, Utah State University, 2007). Retrieved March 1, 2009, from http://www.archive.org/details/randolph_dissertation</p>

        <p id="23">Randolph, J. J. (2007b). <a href = "http://pbi.sagepub.com/content/9/2/113.full.pdf+html">Meta-analysis of the effects of response cards on student achievement, participation, and intervals of off-task behavior.</a> Journal of Positive Behavior Interventions, 9(2), 113-128.</p>

        <p id="24">Randolph, J. J. (2007c). <a href = "http://justus.randolph.name/methods">Multidisciplinary methods in educational technology research and development.</a> Hämeenlinna, Finland: HAMK Press. Retrieved March 1, 2008, from http://justus.randolph.name/methods</p>

        <p id="25">Rosenthal, R. (1991). <a href = "http://books.google.com/books/about/Meta_Analytic_Procedures_for_Social_Rese.html?id=-4CVIVsBSiIC">Meta-analytic procedures for social research.</a> Rev. ed. Newbury Park, CA: Sage.</p>

        <p id="26">Slavin, R. E. (1986). <a href = "http://edr.sagepub.com/content/15/9/5.short">Best-evidence synthesis: An alternative to meta-analysis and traditional reviews.</a> Educational Researcher, 15(9), 5-11.</p>

    </article>
</div>
{% endblock %}